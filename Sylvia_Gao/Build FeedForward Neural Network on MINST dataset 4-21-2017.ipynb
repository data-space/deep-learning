{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build FeedForward Neural Network on MINST Dataset 4/21/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Author Sylvia Gao, Deep Learning Reasearch Assistant from Data Lab \n",
    "\n",
    "Reference:\n",
    "1. MINST for beginners (https://www.tensorflow.org/get_started/mnist/beginners)\n",
    "2. Keras Tutorial: The Ultimate Beginner's Guide to Deep Learning in Python (https://elitedatascience.com/keras-tutorial-deep-learning-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This is the first section of serial tutorial about how to build different type of feedforward neural network. In this section, we will know:\n",
    "1. what is the MINST dataset\n",
    "2. how to build the simplest feedforward neural network on MINST dataset\n",
    "3. Training the model\n",
    "4. Test trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "## Before build the model:\n",
    "\n",
    "1. Be sure to install keras before starting this tutorial\n",
    "2. Be sure you have basic knowledge about feedforward neural network (FNN), which includes:\n",
    "     \n",
    "     The structure of Neural Network; Activation Function; Loss Function; Dropout; Regularization\n",
    "     \n",
    "If not, please see some introduction materials about feed forward neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.Get to know about MINST dataset\n",
    "\n",
    "MNIST is a simple computer vision dataset. It consists of images of handwritten digits like these:\n",
    "<img src='http://rodrigob.github.io/are_we_there_yet/build/images/mnist.png?1363085077'>\n",
    "\n",
    "It also includes the label, telling us which digit it is, for example, the labels of images in the first line are 1, 1, 5, 4, 3\n",
    "\n",
    "In this tutorial, we're going to train a feedforwar neural network model to look at images and predict what digits they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.how to build the simplest feedforward neural network on MINST dataset\n",
    "\n",
    "In this section, we will build feedforward neural network model to predict the handwriting digits. The key recipes for the model are:\n",
    "-  normalizing dataset to range [0,1]\n",
    "-  two hidden layer\n",
    "-  activation function is:Relu\n",
    "-  the loss function is:cross entropy\n",
    "-  dropout rate is 0\n",
    "-  use none regulization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.1 import packages for preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras.callbacks as cb\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#import the core layers from Keras,these are the layers used most common in NN model.\n",
    "from keras.layers.core import Activation, Dense, Dropout\n",
    "\n",
    "#import Sequential model type from Keras. \n",
    "#This is a linear stack of neural network layers, and good for FNN model.\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.utils import np_utils\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#import numpy \n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2 Preporcessing\n",
    "\n",
    "In this section, we will load the MINST dataset.Since each image is 28 pixels by 28 pixels. \n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/MNIST-Matrix.png\">\n",
    "We can interpret this as a big array of numbers. Then we can flatten this array into a vector of 28x28 = 784 numbers. We also need to transform the labels to a binary vector.\n",
    "\n",
    "The result is that mnist.train.images is a tensor (an n-dimensional array) with a shape of [55000, 784]. The first dimension is an index into the list of images and the second dimension is the index for each pixel in each image. Each entry in the tensor is a pixel intensity between 0 and 1, for a particular pixel in a particular image.\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/mnist-train-xs.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def PreprocessDataset():\n",
    "    from sklearn import preprocessing\n",
    "    from numpy._distributor_init import NUMPY_MKL \n",
    "    ## Load pre-shuffled MINST data into train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    ## Transform labels from 1-dimensional class arrays to 10-dimensional class matrices\n",
    "    ## i.e., from '7' to [0,0,0,0,0,0,0,1,0,0]\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    ## Process features. Convert data type and normalize values\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    ## Reshape from a matrix of 28 x 28 pixels to 1-D vector of 784 dimensions\n",
    "    x_train = np.reshape(x_train, (60000, 784))\n",
    "    x_test = np.reshape(x_test, (10000, 784))\n",
    "    ## Min-Max Normalize value to [0, 1]\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = PreprocessDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then lets see what the data will look like after we transform handwriting picture after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     x                      |  y  \n",
      "==================================================\n",
      "0.00 0.00 ... 0.49 0.53 0.69 ...  0.00 0.00 |  0\n",
      "0.00 0.00 ... 0.99 0.99 0.99 ...  0.00 0.00 |  1\n",
      "0.00 0.00 ... 0.00 0.00 0.00 ...  0.00 0.00 |  0\n",
      "0.00 0.00 ... 0.00 0.00 0.49 ...  0.00 0.00 |  0\n",
      "0.00 0.00 ... 0.00 0.00 0.00 ...  0.00 0.00 |  0\n",
      "0.00 0.00 ... 0.10 0.39 0.48 ...  0.00 0.00 |  0\n",
      "0.00 0.00 ... 0.00 0.00 0.00 ...  0.00 0.00 |  0\n",
      "0.00 0.00 ... 0.99 0.99 0.99 ...  0.00 0.00 |  0\n",
      "0.00 0.00 ... 0.00 0.00 0.00 ...  0.00 0.00 |  0\n",
      "0.00 0.00 ... 0.00 0.00 0.00 ...  0.00 0.00 |  0\n"
     ]
    }
   ],
   "source": [
    "## Show part of training data: features and labels\n",
    "## Each row is a sample, and each column represents a feature.\n",
    "print(\"{:^43}\".format(\"x\"), \"|\", \"{:^4}\".format(\"y\"))\n",
    "print(\"=\"*50)\n",
    "for sample_id in range(10):\n",
    "    print(\"{:.2f} {:.2f} ... {:.2f} {:.2f} {:.2f} ...  {:.2f} {:.2f}\".format(\n",
    "            x_train[sample_id][0], x_train[sample_id][1],\n",
    "            x_train[sample_id][156], x_train[sample_id][157], x_train[sample_id][158],\n",
    "            x_train[sample_id][-2], x_train[sample_id][-1]), \"| \",\n",
    "           \"{:.0f}\".format(y_train[sample_id][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.3 Define the model:\n",
    "\n",
    "Now lets define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def DefineModel():\n",
    "    ##Number of layers:2\n",
    "    first_layer_width = 128\n",
    "    second_layer_width = 64    \n",
    "    \n",
    "    ##Activation Function:Relu\n",
    "    activation_func = 'relu' \n",
    "  \n",
    "    ##Loss Function:cross entropy.\n",
    "    loss_function = 'categorical_crossentropy'\n",
    "    \n",
    "    ##Dropout rate:0\n",
    "    dropout_rate = 0.0\n",
    "    \n",
    "    ##Regularization:\n",
    "    # weight_regularizer = None\n",
    "    weight_regularizer = None\n",
    "\n",
    "    ##Learning Rate:0.1\n",
    "    learning_rate = 0.1\n",
    "    \n",
    "    ## Initialize model.\n",
    "    model = Sequential()\n",
    "\n",
    "    ## First hidden layer with 'first_layer_width' neurons. \n",
    "    ## Also need to specify input dimension.\n",
    "    ## 'Dense' means fully-connected.\n",
    "    model.add(Dense(first_layer_width, input_dim=784, W_regularizer=weight_regularizer))\n",
    "    model.add(Activation(activation_func))\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "    ## Second hidden layer.\n",
    "    if second_layer_width > 0:\n",
    "        model.add(Dense(second_layer_width))\n",
    "        model.add(Activation(activation_func))\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(0.5))         \n",
    "    \n",
    "    ## Last layer has the same dimension as the number of classes\n",
    "    model.add(Dense(10))\n",
    "    ## For classification, the activation is softmax\n",
    "    model.add(Activation('softmax'))\n",
    "    ## Define optimizer. In this tutorial/codelab, we select SGD.\n",
    "    ## You can also use other methods, e.g., opt = RMSprop()\n",
    "    opt = SGD(lr=learning_rate, clipnorm=5.)\n",
    "    ## Define loss function = 'categorical_crossentropy' or 'mean_squared_error'\n",
    "    model.compile(loss=loss_function, optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.4 Define Mini-batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def TrainModel(data=None, epochs=20):\n",
    "    ##Mini-batch:\n",
    "    ##uses mini-batch of size 128.\n",
    "    ##batch = 128\n",
    "\n",
    "    batch=128\n",
    "    start_time = time.time()\n",
    "    model = DefineModel()\n",
    "    if data is None:\n",
    "        print(\"Must provide data.\")\n",
    "        return\n",
    "    x_train, x_test, y_train, y_test = data\n",
    "    print('Start training.')\n",
    "    ## Use the first 55,000 (out of 60,000) samples to train, last 5,500 samples to validate.\n",
    "    history = model.fit(x_train[:55000], y_train[:55000], nb_epoch=epochs, batch_size=batch,\n",
    "              validation_data=(x_train[55000:], y_train[55000:]))\n",
    "    print(\"Training took {0} seconds.\".format(time.time() - start_time))\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trained_model, training_history = TrainModel(data=[x_train, x_test, y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1 Define Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def PlotHistory(train_value, test_value, value_is_loss_or_acc):\n",
    "    f, ax = plt.subplots()\n",
    "    ax.plot([None] + train_value, 'o-')\n",
    "    ax.plot([None] + test_value, 'x-')\n",
    "    ## Plot legend and use the best location automatically: loc = 0.\n",
    "    ax.legend(['Train ' + value_is_loss_or_acc, 'Validation ' + value_is_loss_or_acc], loc = 0) \n",
    "    ax.set_title('Training/Validation ' + value_is_loss_or_acc + ' per Epoch')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(value_is_loss_or_acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 observe training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PlotHistory(training_history.history['loss'], training_history.history['val_loss'], 'Loss')\n",
    "PlotHistory(training_history.history['acc'], training_history.history['val_acc'], 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.3 observe regulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def drawWeightHistogram(x):\n",
    "    ## the histogram of the data\n",
    "    fig = plt.subplots()\n",
    "    n, bins, patches = plt.hist(x, 50)\n",
    "    plt.xlim(-0.5, 0.5)\n",
    "    plt.xlabel('Weight')\n",
    "    plt.ylabel('Count')\n",
    "    zero_counts = (x == 0.0).sum()\n",
    "    plt.title(\"Weight Histogram. Num of '0's: %d\" % zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w1 = trained_model.layers[0].get_weights()[0].flatten()\n",
    "drawWeightHistogram(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.Define Testing Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def TestModel(model=None, data=None):\n",
    "    if model is None:\n",
    "        print(\"Must provide a trained model.\")\n",
    "        return\n",
    "    if data is None:\n",
    "        print(\"Must provide data.\")\n",
    "        return\n",
    "    x_test, y_test = data\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5.Test Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_score = TestModel(model=trained_model, data=[x_test, y_test])\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ShowInputImage(data):\n",
    "    \"\"\"Visualize input image.\"\"\"\n",
    "    plot = plt.figure()\n",
    "    plot.set_size_inches(2,2)\n",
    "    plt.imshow(np.reshape(-data, (28,28)), cmap='Greys_r')\n",
    "    plt.title(\"Input\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def ShowHiddenLayerOutput(input_data, target_layer_num):\n",
    "    \"\"\"Visualize output from the target hidden layer.\"\"\"\n",
    "    from keras import backend as K\n",
    "    ## Backend converter: to TensorFlow\n",
    "    target_layer = K.function(trained_model.inputs, [trained_model.layers[target_layer_num].output])\n",
    "    ## Extract output from the target hidden layer.\n",
    "    target_layer_out = target_layer([input_data])\n",
    "    plot = plt.figure()\n",
    "    plot.set_size_inches(2,2)\n",
    "    plt.imshow(np.reshape(-target_layer_out[0][0], (16,-1)), cmap='Greys_r')\n",
    "    plt.title(\"Hidden layer \" + str(target_layer_num))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def ShowFinalOutput(input_data):\n",
    "    \"\"\"Calculate final prediction.\"\"\"\n",
    "    from keras import backend as K\n",
    "    ## Backend converter: to TensorFlow\n",
    "    ## Calculate final prediction.\n",
    "    last_layer = K.function(trained_model.inputs, [trained_model.layers[-1].output])\n",
    "    last_layer_out = last_layer([input_data])\n",
    "    print(\"Final prediction: \" + str(np.argmax(last_layer_out[0][0])) )\n",
    "\n",
    "ShowInputImage(x_test[0])\n",
    "ShowHiddenLayerOutput(x_test, 1)\n",
    "ShowFinalOutput(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
